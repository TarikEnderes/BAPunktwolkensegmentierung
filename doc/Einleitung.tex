\chapter{Einleitung}
	Für zahlreiche Entwicklungsthemen der heutigen Zeit, wie beispielsweise autonomes Fahren, ist eine präzise Erkennung der Umweltbedingungen unerlässlich. Kameras und Laserscanner finden für diesen Zweck oft Verwendung, was die Verarbeitung von Bildern und Punktwolken zu einem verbreiteten Gegenstand moderner Forschung macht. Häufig wird zur Lösung dieser komplexen Probleme auf Elemente der Neuroinformatik zurückgegriffen. \\
	Je nach Anwendungsfeld ist ein bestimmter Grad an Auswertung der gegebenen Daten erforderlich. Diese Arbeit befasst sich mit der Aufgabe, Bilder und Punktwolken zu segmentieren.
	\section{Segmentierung}
		Segmentierung bezeichnet einen Vorgang, bei dem ein Bild nach bestimmten Homogenitätskriterien in inhaltlich zusammenhängende Regionen eingeteilt wird. Von den verschiedenen Ansätzen, die das erreichen sollen, befasst sich diese Arbeit mit pixelbasierten Verfahren, bei denen jedem Pixel in einem Bild eine Klasse zugeordnet wird. Man unterscheidet zwischen den in \cite{UPSNet} beschriebenen, semantische Segmentierung, Instanz-Segmentierung und panoptische Segmentierung und der in \cite{DBLP:journals/corr/abs-1904-09172} ausgeführten Objekt-Segmentierung. Für weitere Informationen siehe \cite{gonzalez2008digital}.
		\subsection{Semantische Segmentierung}
			Bei der semantischen Segmentierung soll jeder Pixel eine valide Klasse erhalten. Es wird dabei nicht zwischen unterschiedlichen Instanzen einer Objektklasse unterschieden. Wenn beispielsweise auf einem Bild zwei Fahrzeuge zu sehen sind und bei der Segmentierung die Klasse "`Fahrzeug"' zugeteilt werden soll, erhalten die Pixel beider Fahrzeuge das Label "`Fahrzeug"'. Die Anzahl valider Klassen bleibt somit bei jeden prozessierten Bild gleich.\\ Einige Anwendungsgebiete von semantischer Segmentierung sind autonomes Fahren im Gelände \cite{OffRoad}, Zellanalyse in der Biomedizin \cite{journals/corr/RonnebergerFB15} und Auswertung von Satellitenbildern für Kartographie \cite{DBLP:journals/corr/abs-1904-03983}.
		\subsection{Instanz-Segmentierung}
			Im Gegensatz zur semantischen Segmentierung werden bei der Instanz-Segmentierung nur zählbare Objekte betrachtet und deren Instanzen berücksichtigt. Übertragen auf vorheriges Beispiel würden die Pixel des einen Fahrzeug ein Label wie "`Fahrzeug1"' und die des anderen analog "`Fahrzeug2"' erhalten.\\
			Instanz-Segmentierung findet beispielsweise Anwendung zur Detektion von Personen in Videodaten für Verhaltensanalysen und Überwachung \cite{HumanSegmentation}.
		\subsection{Panoptische Segmentierung}
			Die panoptische Segmentierung stellt eine Kombination der vorherigen Segmentations-Arten dar. Zählbare Objekte werden demnach nach dem Prinzip der Instanz-Segmentierung und amorphe nach dem der semantischen Segmentierung segmentiert. Die Ergebnisse beider Verfahren werden anschließend kombiniert.
		\subsection{Objekt-Segmentierung}
			Bei der Objekt-Segmentierung soll für jeden Pixel eines Bildes entschieden werden, ob er Teil des Vorder- oder des Hintergrundes ist, weshalb sie häufig als Vordergrund-Hintergrund-Segmentierung bezeichnet wird. Von Interesse ist dabei nur, wo sich Objekte im Bild befinden, nicht, wie bei den anderen Disziplinen, worum es sich handelt. Oft ist das Ziel dabei die Erkennung von Bewegung in Videodaten.\\
			Objekt-Segmentierung findet Verwendung im Bereich der Videoüberwachung \cite{ObjSegmentation}.
		
	\section{Ziele und Anforderunen}
		Ziel der Arbeit ist es, ein System zu entwickel, das mit Hilfe von neuronalen Netzen jedem Punkt einer Punktwolke eine Klasse zuweist. Dazu soll ein Bild semantisch segmentiert und die so erhaltenen Ergebnisse auf eine analog dazu aufgenommene Punktwolke projiziert werden. Mit diesem Vorgehen soll die Entwicklung im Bereich der digitalen Bildsegmentierung der letzten Jahre ausgenutzt werden. Für die Ausführung dieses Verfahrens sind offensichtlich sowohl Bilder als auch Punktwolken zur Erkennung eines Szenarios notwendig. Entsprechend werden Daten aus mehreren Sensoren wie Stereo-Kameras und Laserscannern benötigt. Ein Aufgabe wird also sein, einen entsprechenden Datensatz auszuwählen, der diese Anforderungen erfüllt.\\
		Der Anwendungsbereich des Systems soll autonomes Fahren sein, weshalb Entwicklung und Experimente mit Datensätzen für diesen durchgeführt werden sollen. Besondere Wichtigkeit kommt daher der Erkennung von Fahrzeugen, Personen und Straßen zu, da diese den größten Einfluss auf Entscheidungen bezüglich des Verhaltens im Straßenverkehr haben. Eine Kernanforderung ist dabei Echtzeitfähigkeit. Optimierung der Laufzeit hat dem entsprechend Priorität. Weiterhin soll das System transportabel, leicht zu verwenden, benutzerfreundlich und ressourcenschonend sein.\\
		Die Entwicklung des Systems in Python soll die Implementierung transportabel machen. Dazu sollen Zeitintensive Berechnungen durch CUDA-Unterstützung auf die Grafikkarte ausgelagert werden, was für die Verbesserung der Laufzeit essentiell und bei der Verwendung Neuronaler Netze üblich ist. Als Framework zur Bildsegmentierung soll DeepLab genutzt werden, das zur Zeit der Entstehung dieser Arbeit als State-of-the-Art angesehen wird. Den Backbone dafür soll MobileNetV2 bilden, eine ressourcenschonende Netzwerkarchitektur, die sich durch Geschwindigkeit auszeichnet. \\
		Nach der Entwicklung des Systems sollen dessen Eigenschaften durch Experimente genauer untersucht und diskutiert werden. Im Vordergrund steht dabei die Untersuchung des Neuronalen Netzes. Die Eigenschaften von MobileNetV2 sollen ausgewertet und mit denen der Architektur Xception65 verglichen werden. Außerdem sollen die Auswirkungen verschiedener Trainingsmuster ermittelt werden. 